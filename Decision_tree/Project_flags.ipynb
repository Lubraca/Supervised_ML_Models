{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc906b8b",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/40/flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecademylib3\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\n",
    "cols = ['name','landmass','zone', 'area', 'population', 'language','religion','bars','stripes','colours',\n",
    "'red','green','blue','gold','white','black','orange','mainhue','circles',\n",
    "'crosses','saltires','quarters','sunstars','crescent','triangle','icon','animate','text','topleft','botright']\n",
    "df= pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/flags/flag.data\", names = cols)\n",
    "\n",
    "#variable names to use as predictors\n",
    "var = [ 'red', 'green', 'blue','gold', 'white', 'black', 'orange', 'mainhue','bars','stripes', 'circles','crosses', 'saltires','quarters','sunstars','triangle','animate']\n",
    "\n",
    "#Print number of countries by landmass, or continent\n",
    "print(df.landmass.value_counts())\n",
    "\n",
    "#Create a new dataframe with only flags from Europe and Oceania\n",
    "df_36 = df[df[\"landmass\"].isin([3,6])]\n",
    "\n",
    "#Print the average vales of the predictors for Europe and Oceania\n",
    "print(df_36.groupby('landmass')[var].mean().T)\n",
    "\n",
    "#Create labels for only Europe and Oceania\n",
    "df_36 = df[df[\"landmass\"].isin([3,6])]\n",
    "labels = df_36[\"landmass\"]\n",
    "\n",
    "#Print the variable types for the predictors\n",
    "print(df[var].dtypes)\n",
    "\n",
    "#Create dummy variables for categorical predictors\n",
    "data = pd.get_dummies(df_36[var])\n",
    "\n",
    "#Split data into a train and test set\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=1, test_size=.4)\n",
    "\n",
    "#Fit a decision tree for max_depth values 1-20; save the accuracy score in acc_depth\n",
    "depths = range(1, 21)\n",
    "acc_depth = []\n",
    "for i in depths:\n",
    "    dt = DecisionTreeClassifier(random_state = 10, max_depth = i)\n",
    "    dt.fit(train_data, train_labels)\n",
    "    acc_depth.append(dt.score(test_data, test_labels))\n",
    "\n",
    "#Plot the accuracy vs depth\n",
    "plt.plot(depths, acc_depth)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "#Find the largest accuracy and the depth this occurs\n",
    "max_acc = np.max(acc_depth)\n",
    "best_depth = depths[np.argmax(acc_depth)]\n",
    "print(f'Highest accuracy {round(max_acc,3)*100}% at depth {best_depth}')\n",
    "\n",
    "#Refit decision tree model with the highest accuracy and plot the decision tree\n",
    "plt.figure(figsize=(14,8))\n",
    "dt = DecisionTreeClassifier(random_state = 1, max_depth = best_depth)\n",
    "dt.fit(train_data, train_labels)\n",
    "tree.plot_tree(dt, feature_names = train_data.columns,  \n",
    "               class_names = ['Europe', 'Oceania'],\n",
    "                filled=True)\n",
    "plt.show()\n",
    "\n",
    "#Create a new list for the accuracy values of a pruned decision tree.  Loop through\n",
    "#the values of ccp and append the scores to the list\n",
    "acc_pruned = []\n",
    "ccp = np.logspace(-3, 0, num=20)\n",
    "for i in ccp:\n",
    "    dt_prune = DecisionTreeClassifier(random_state = 1, max_depth = best_depth, ccp_alpha=i)\n",
    "    dt_prune.fit(train_data, train_labels)\n",
    "    acc_pruned.append(dt_prune.score(test_data, test_labels))\n",
    "\n",
    "plt.plot(ccp, acc_pruned)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ccp_alpha')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "#Find the largest accuracy and the ccp value this occurs\n",
    "max_acc_pruned = np.max(acc_pruned)\n",
    "best_ccp = ccp[np.argmax(acc_pruned)]\n",
    "\n",
    "print(f'Highest accuracy {round(max_acc_pruned,3)*100}% at ccp_alpha {round(best_ccp,4)}')\n",
    "\n",
    "#Fit a decision tree model with the values for max_depth and ccp_alpha found above\n",
    "dt_final = DecisionTreeClassifier(random_state = 1, max_depth = best_depth, ccp_alpha=best_ccp)\n",
    "dt_final.fit(train_data, train_labels)\n",
    "\n",
    "#Plot the final decision tree\n",
    "plt.figure(figsize=(14,8))\n",
    "tree.plot_tree(dt_final, feature_names = train_data.columns,  \n",
    "               class_names = ['Europe', 'Oceania'],\n",
    "                filled=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

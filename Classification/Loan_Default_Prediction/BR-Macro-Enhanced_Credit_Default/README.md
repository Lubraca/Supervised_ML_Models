# ğŸ‡§ğŸ‡· Macro-Enhanced Credit Default Risk Model  
### An MLOps Learning Project

This repository documents an **end-to-end Machine Learning & MLOps learning project**, focused on building, evaluating, and deploying a **credit default risk model** while rigorously testing the hypothesis that **macroeconomic features improve predictive performance**.

The project prioritizes **methodological rigor, reproducibility, and production-oriented thinking**, even when experimental results do **not** confirm the initial hypothesis.

---

## ğŸ¯ Project Goal

To evaluate whether augmenting a **client-level (micro) credit dataset** with **Brazilian macroeconomic indicators** improves the predictive performance of a loan default model.

**Initial hypothesis**:  
> The combination of micro-level borrower data and macroeconomic indicators (e.g., inflation, interest rates) improves AUC/ROC performance.

**Final conclusion**:  
> After systematic experimentation and feature selection, **macroeconomic variables did not improve the modelâ€™s predictive power**.  
> The final optimized model relies exclusively on **micro-level features**.

This outcome is explicitly documented as part of the learning process.

---

## ğŸ§ª Experimental Outcome (Key Insight)

- Macroeconomic variables were engineered, lagged, and tested
- Multiple model configurations were evaluated
- Feature importance analysis and validation metrics showed **no statistically or practically meaningful performance gain**
- The final model contains **12 features**, **none of which are macroeconomic**

This reinforces an important real-world lesson:  
**Not all theoretically relevant features add predictive signal in practice**.

---

## ğŸš€ Repository Structure (MLOps-Oriented)

This project follows **MLOps best practices**, clearly separating experimentation, training artifacts, and serving logic:

project-root/n
â”‚/n
â”œâ”€â”€ data/ # Raw and processed datasets (Kaggle + BCB time series)/n
â”œâ”€â”€ notebooks/ # Exploratory analysis and modeling notebooks (01 â†’ 06)/n
â”œâ”€â”€ src/ # Production-ready Python modules/n
â”‚ â”œâ”€â”€ predict.py # Inference pipeline (PredictionHandler)/n
â”‚ â””â”€â”€ schemas.py # Pydantic input/output schemas/n
â”‚/n
â”œâ”€â”€ models/ # MLOps artifacts/n
â”‚ â”œâ”€â”€ model.pkl/n
â”‚ â”œâ”€â”€ target_encoder.pkl/n
â”‚ â””â”€â”€ imputation_map.json/n
â”‚/n
â”œâ”€â”€ Dockerfile # Reproducible serving environment/n
â”œâ”€â”€ PLANNING.md # Execution plan and project phases/n
â”œâ”€â”€ README.md # Project overview/n


---

## ğŸ“Š Modeling & Feature Engineering Highlights

To handle a high-dimensional credit dataset, the following techniques were applied:

### Feature Engineering
- Financial ratios such as:
  - Credit / Income
  - Annuity / Income
- Correction of known data anomalies (e.g., `DAYS_EMPLOYED` sentinel values)

### Categorical Encoding
- **Target Encoding** was used instead of One-Hot Encoding
- Reduced dimensionality dramatically
- Improved stability and performance of tree-based models

### Model Choice
- **LightGBM (`LGBMClassifier`)**
- Selected for:
  - Strong performance on tabular data
  - Fast training
  - Compatibility with production inference pipelines

---

## ğŸ§  Final Model Summary

- **Problem type**: Binary classification (default vs. non-default)
- **Metric focus**: ROC-AUC
- **Final feature count**: 12
- **Macroeconomic features used**: âŒ None
- **Reason**: No demonstrated predictive gain

This decision reflects **evidence-based feature selection**, not theoretical preference.

---

## ğŸŒ MLOps Deployment Pipeline (FastAPI & Docker)

The final model is deployed as a **production-style microservice**, emphasizing trainingâ€“serving parity.

| Component | Technology | Role |
|--------|------------|------|
| API Layer | FastAPI | Exposes `/predict` endpoint with schema validation |
| Inference Logic | PredictionHandler | Applies preprocessing, encoding, and prediction consistently |
| Artifacts | joblib / JSON | Model, encoder, and imputation maps |
| Runtime | Docker | Reproducible, containerized serving environment |

---

## ğŸ› ï¸ Development Environment

This project was developed using a **remote-first workflow**:

1. **VS Code Remote Development**
2. **Google Colab VM** as the main compute environment
3. **GitHub** for version control (PAT-based authentication)

This setup mirrors real-world constraints where training and serving often occur on different machines.

---

## ğŸ’¡ Learning Outcomes

This project demonstrates:

- How to test and **reject a hypothesis responsibly**
- The importance of **trainingâ€“serving parity**
- Proper management of **ML artifacts**
- Clean separation between experimentation and production code
- How MLOps adds value even when model performance plateaus

---

## ğŸ”œ Next Steps (Deployment Track)

Current focus: **MLOps completion**, not model tuning.

- [x] Save final model and preprocessing artifacts
- [x] Implement PredictionHandler
- [ ] Finalize and test Dockerfile
- [ ] Run containerized API locally
- [ ] (Optional) Add CI/CD and monitoring

---

## ğŸ‘¤ Author

**Lucas Casarin**  
Economist | Machine Learning | MLOps-Oriented Analytics Engineering  

This repository is part of my professional portfolio and reflects **realistic ML system development**, including failed hypotheses, engineering trade-offs, and production concerns.



{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f50c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import Field, create_model, BaseModel\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49722b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully added 'src' directory to Python path.\n"
     ]
    }
   ],
   "source": [
    "# Define project Path in Colab\n",
    "PROJECT_BASE_PATH = '/content/drive/MyDrive/Project_01' \n",
    "\n",
    "# ADD 'src' DIRECTORY TO PYTHON PATH\n",
    "SRC_PATH = os.path.join(PROJECT_BASE_PATH, 'src')\n",
    "\n",
    "# verify if SRC_PATH is already in sys.path\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "    print(\"✅ Successfully added 'src' directory to Python path.\")\n",
    "\n",
    "# IMPORT Paths CLASS FROM config MODULE\n",
    "from config import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd01960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Project configuration (Paths) initialized successfully.\n",
      "Raw Data Path check: /content/drive/MyDrive/Project_01/data/raw/application_train.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from config import Paths\n",
    "    \n",
    "    cfg = Paths(PROJECT_BASE_PATH)\n",
    "    cfg.create_dirs() \n",
    "    \n",
    "    print(\"\\n✅ Project configuration (Paths) initialized successfully.\")\n",
    "    print(f\"Raw Data Path check: {cfg.TRAIN_RAW_FILE}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"❌ Error: Could not import Paths from config module.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692fa6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df_train = pd.read_csv(\n",
    "    os.path.join(\n",
    "        cfg.REPORT_DIR, 'data_train_schema.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c9a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dtypes_dict = {}\n",
    "\n",
    "for index, row in schema_df_train.iterrows():\n",
    "    # Access columns using the dictionary-like structure of 'row'\n",
    "    feature_name = row['feature_name']\n",
    "    data_type = row['data_type']\n",
    "    \n",
    "    features_dtypes_dict[feature_name] = data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3d9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Utility Functions (Map Dtypes) ---\n",
    "def map_pandas_to_python_type(pandas_dtype: np.dtype) -> Any:\n",
    "    # ... (Insert the full map_pandas_to_python_type function here) ...\n",
    "    dtype_str = str(pandas_dtype)\n",
    "    if 'int' in dtype_str:\n",
    "        return Optional[int]\n",
    "    # ... (rest of mapping logic) ...\n",
    "    elif 'float' in dtype_str:\n",
    "        return Optional[float]\n",
    "    elif 'object' in dtype_str:\n",
    "        return Optional[str]\n",
    "    else:\n",
    "        return Optional[Any]\n",
    "\n",
    "def generate_schemas_file(schema_df: pd.DataFrame, output_path: str):\n",
    "    \n",
    "    # 2. Convert DataFrame to Pydantic Fields Dictionary\n",
    "    pydantic_fields = {}\n",
    "    for row in schema_df.itertuples():\n",
    "        feature_name = row.feature_name\n",
    "        dtype = row.data_type # Assuming data_type is stored as a string like 'float64'\n",
    "        \n",
    "        if feature_name == 'TARGET':\n",
    "            continue\n",
    "            \n",
    "        pydantic_type = map_pandas_to_python_type(np.dtype(dtype)) # Convert string back to dtype object\n",
    "\n",
    "        if feature_name == 'SK_ID_CURR':\n",
    "            field_definition = (int, Field(..., description=\"Unique ID of the application (MANDATORY).\"))\n",
    "        elif pydantic_type in (Optional[str], Optional[int], Optional[float]):\n",
    "            field_definition = (pydantic_type, None) # Default to None for optional fields\n",
    "        else:\n",
    "            field_definition = (pydantic_type, None) # Default to None for safety\n",
    "\n",
    "        pydantic_fields[feature_name] = field_definition\n",
    "        \n",
    "    # 3. Dynamically Create the Model\n",
    "    LoanApplicationRawInput = create_model(\n",
    "        'LoanApplicationRawInput', \n",
    "        __base__= BaseModel, # Assuming BaseModel is available\n",
    "        **pydantic_fields\n",
    "    )\n",
    "\n",
    "    # 4. Generate the source code representation\n",
    "    # Pydantic doesn't have a direct 'to_code' method for dynamic classes, \n",
    "    # so we manually format the class string.\n",
    "    \n",
    "    # Start the class definition string\n",
    "    class_definition = (\n",
    "        \"from pydantic import BaseModel, Field\\n\"\n",
    "        \"from typing import Optional, List\\n\\n\"\n",
    "        \"class LoanApplicationRawInput(BaseModel):\\n\"\n",
    "    )\n",
    "    \n",
    "    # Add each feature as a field string\n",
    "    for name, definition in pydantic_fields.items():\n",
    "        type_str = str(definition[0]).replace(\"typing.\", \"\") # Clean up Optional[Type] string\n",
    "        \n",
    "        # Determine if it's a required field or defaults to None\n",
    "        if definition[1] is ...:\n",
    "            default_str = f\"Field(..., description='{definition[1].description}')\"\n",
    "        elif definition[1] is None:\n",
    "            default_str = \"None\"\n",
    "        else:\n",
    "             # Handle other defaults if necessary\n",
    "             default_str = str(definition[1])\n",
    "             \n",
    "        class_definition += f\"    {name}: {type_str} = {default_str}\\n\"\n",
    "\n",
    "    # Add the Response model for completeness\n",
    "    class_definition += (\n",
    "        \"\\nclass PredictionResponse(BaseModel):\\n\"\n",
    "        \"    SK_ID_CURR: int\\n\"\n",
    "        \"    probability_of_default: float\\n\"\n",
    "    )\n",
    "\n",
    "    # 5. Write the definition to schemas.py\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(class_definition)\n",
    "        \n",
    "    print(f\"✅ Successfully generated schemas.py at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c011f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully generated schemas.py at /content/drive/MyDrive/Project_01/src/schemas.py\n"
     ]
    }
   ],
   "source": [
    "generate_schemas_file(schema_df_train, os.path.join(cfg.SRC_DIR, 'schemas.py'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
